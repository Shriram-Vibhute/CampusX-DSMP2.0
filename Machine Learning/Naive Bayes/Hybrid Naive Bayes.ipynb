{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ba3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6c30ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "from seaborn.utils import load_dataset\n",
    "df = load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79182e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df = df.drop(['deck', 'alive'], axis=1)  # Assign result back\n",
    "df = df.dropna()  # Now removes much less data\n",
    "df['age'] = df['age'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b74efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     712 non-null    int64   \n",
      " 1   pclass       712 non-null    int64   \n",
      " 2   sex          712 non-null    object  \n",
      " 3   age          712 non-null    int32   \n",
      " 4   sibsp        712 non-null    int64   \n",
      " 5   parch        712 non-null    int64   \n",
      " 6   fare         712 non-null    float64 \n",
      " 7   embarked     712 non-null    object  \n",
      " 8   class        712 non-null    category\n",
      " 9   who          712 non-null    object  \n",
      " 10  adult_male   712 non-null    bool    \n",
      " 11  embark_town  712 non-null    object  \n",
      " 12  alone        712 non-null    bool    \n",
      "dtypes: bool(2), category(1), float64(1), int32(1), int64(4), object(4)\n",
      "memory usage: 60.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data Information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c1fd2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = ['survived'], axis = 0), df[['survived']], random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedNaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha  # Laplace smoothing strength\n",
    "        \n",
    "    def fit(self, X_num, X_cat, y):\n",
    "        \"\"\"Train the model.\n",
    "        X_num: Numerical features (n_samples x n_num_features)\n",
    "        X_cat: Categorical features (n_samples x n_cat_features)\n",
    "        y: Target labels (n_samples)\n",
    "        \"\"\"\n",
    "        # === Step 1: Process classes ===\n",
    "        self.classes = np.unique(y) # array([0, 1])\n",
    "        self.n_classes = len(self.classes) # 2\n",
    "        \n",
    "        # Prior probability P(y)\n",
    "        self.class_priors = np.zeros(self.n_classes)\n",
    "        for i, c in enumerate(self.classes):\n",
    "            self.class_priors[i] = np.mean(y == c) # array([0.32417582, 0.67582418])\n",
    "        \n",
    "        # === Step 2: Handle numerical features (Gaussian) ===\n",
    "        # For each class, compute mean/std per feature\n",
    "        self.num_means = np.zeros((self.n_classes, X_num.shape[1]))\n",
    "        self.num_stds = np.zeros((self.n_classes, X_num.shape[1]))\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            # Filter samples for class c\n",
    "            X_class = X_num[(y == c).values.ravel()]\n",
    "            self.num_means[i, :] = np.mean(X_class, axis=0) # array([[64.53213051], [85.8211065 ]])\n",
    "            self.num_stds[i, :] = np.std(X_class, axis=0) + 1e-9  # Avoid zero std\n",
    "\n",
    "        # === Step 3: Handle categorical features (Frequency counts) ===\n",
    "        self.cat_probs = []  # Store probabilities per feature\n",
    "        self.cat_mappings = []  # Store category-to-index mappings\n",
    "        \n",
    "        for j in range(X_cat.shape[1]):  # For each categorical feature\n",
    "            feature_vals = X_cat.iloc[:, j]\n",
    "            unique_vals = np.unique(feature_vals) # 1, 2, 3\n",
    "            mapping = {val: idx for idx, val in enumerate(unique_vals)} # {1: 0, 2: 1, 3: 2}\n",
    "            self.cat_mappings.append(mapping)\n",
    "            \n",
    "            n_cats = len(unique_vals) # 3\n",
    "            prob_matrix = np.zeros((self.n_classes, n_cats))\n",
    "            \n",
    "            for i, c in enumerate(self.classes):\n",
    "                # Filter samples for class c\n",
    "                class_vals = feature_vals[(y == c).values.ravel()] # Yes\n",
    "                \n",
    "                # Count occurrences of each category\n",
    "                counts = np.zeros(n_cats) # [0, 0, 0]\n",
    "                for val in class_vals:\n",
    "                    counts[mapping[val]] += 1\n",
    "                \n",
    "                # Apply Laplace smoothing\n",
    "                counts_smoothed = counts + self.alpha\n",
    "                prob_matrix[i, :] = counts_smoothed / (len(class_vals) + self.alpha * n_cats)\n",
    "                \n",
    "            self.cat_probs.append(prob_matrix)\n",
    "    \n",
    "    def predict(self, X_num, X_cat):\n",
    "        \"\"\"Predict class probabilities for new data\"\"\"\n",
    "        log_probs = np.zeros((X_num.shape[0], self.n_classes)) # n * 2\n",
    "        \n",
    "        for i in range(X_num.shape[0]):  # For each sample\n",
    "            for c_idx in range(self.n_classes):  # For each class\n",
    "                # Start with log prior: log P(y)\n",
    "                log_prob = np.log(self.class_priors[c_idx]) # Just one value for each class\n",
    "                \n",
    "                # === Numerical: Gaussian log PDF ===\n",
    "                # log P(x_num | y) = log of normal distribution PDF\n",
    "                # Likelyhood log probability\n",
    "                log_gauss = norm.logpdf(\n",
    "                    X_num.iloc[i, :], \n",
    "                    loc=self.num_means[c_idx, :], \n",
    "                    scale=self.num_stds[c_idx, :]\n",
    "                )\n",
    "                log_prob += np.sum(log_gauss)\n",
    "\n",
    "                # === Categorical: Sum log probabilities ===\n",
    "                for j in range(X_cat.shape[1]):  # For each cat feature\n",
    "                    val = X_cat.iloc[i, j]\n",
    "                    mapping = self.cat_mappings[j]\n",
    "                    \n",
    "                    if val in mapping:\n",
    "                        # Get P(x_cat | y) from precomputed matrix\n",
    "                        prob_val = self.cat_probs[j][c_idx, mapping[val]]\n",
    "                        log_prob += np.log(prob_val)\n",
    "                    else:\n",
    "                        # Unseen category: use uniform probability\n",
    "                        n_cats = len(self.cat_mappings[j])\n",
    "                        log_prob += np.log(1 / n_cats)  # Fallback\n",
    "                \n",
    "                log_probs[i, c_idx] = log_prob\n",
    "        \n",
    "        # Return class with highest log probability\n",
    "        return self.classes[np.argmax(log_probs, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c33ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Numerical and Categorical columns\n",
    "X_train_num = X_train.select_dtypes(include = [\"float\"])\n",
    "X_train_cat = X_train.select_dtypes(include = [\"object\", \"int\", \"category\"])\n",
    "\n",
    "X_test_num = X_test.select_dtypes(include = [\"float\"])\n",
    "X_test_cat = X_test.select_dtypes(include = [\"object\", \"int\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fea1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedNaiveBayes(alpha = 1.0)\n",
    "model.fit(X_train_num, X_train_cat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a88446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - 0.7584269662921348\n",
      "Precision - 0.7368421052631579\n",
      "Recall - 0.7088607594936709\n",
      "F1 Score - 0.7225806451612903\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "y_pred = model.predict(X_test_num, X_test_cat)\n",
    "print(\"Accuracy -\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision -\", precision_score(y_test, y_pred))\n",
    "print(\"Recall -\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score -\", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
